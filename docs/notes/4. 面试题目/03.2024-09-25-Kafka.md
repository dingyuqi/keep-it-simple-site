---
title: Kafka
icon: /logo/Kafka.png
createTime: 2024/09/25 18:14:09
permalink: /interview/5kl352fe/
---
::: tip 提问
1. 是否有遇到过重复消费的问题? 怎么解决的?
2. 知道流量控制是如何实现的吗?
:::

## 重复消费
### 导致问题的原因
消费重复的本质原因是offset值的丢失, 主要有以下两个场景:
1. **宕机**
   
   customer和broker之间5秒才同步一次offset. 如果出现宕机的清空可能导致offset没有及时提交, 那5秒之间的丢失了.

2. **再均衡机制**
   
   如果customer在5分钟内没有处理完一批消息, 就会触发服务端partition再均衡(Rebalance)机制, 导致offset提交失败.

### 解决方案
1. 提高消费性能避免触发Rebalance.可以使用多线程并发, 调整超时时间还有减少每次从broker上拉取的条数来做到.
2. 使用`ConsumerRebalanceListener`监听, 然后在再均衡前后做收尾工作.
3. 使用消息幂等性
   1. 开启Kafka幂等性功能
   2. 及那个消息生成md5存入Redis, 在每次消费前先检查是否消费过